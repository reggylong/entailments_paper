
Textual inference is a critical factor in
building question-answering systems at web-scale. 
Entailment graphs are a compact method to 
represent a set of globally consistent inference rules. 
In this paper, we consider the task of learning entailment graphs. 
First, we examine the computational difficulties associated
with generating a large dataset for learning such entailment graphs.
We then compare two state of the art relation extraction systems.
Lastly, we propose using coreference resolution for increasing the amount of 
information extracted per sentence. Although more computationally
intensive, using coreference resolution significantly increases
the amount of information extracted.



% Contributions:
% Scaling up relation extractor to a large set of articles
% Show that OpenIE produces more relations
% Demonstrate that replacing pronouns gives a significant boost
% in number of relations extracted
% 


% Outline
% Entailment graphs exciting model to learn textual inference
% Critical component to question-answering systems
%
%
%
