\section{Approach}

\subsection{Dataset}
We use the \newsspike{} dataset collected in \citet{zhang2013parallelparaphrase}.
This dataset is a collection of news article texts, all taken from the months of
Janurary and February in 2013, and contains 546,713 such texts. On average,
each news article contains between 31 and 32 sentences.

\subsection{Pipeline}
We describe the pipeline $p$ that we run on each text $T$. 
\citep{manning2014stanford}
\subsubsection{Tokenizer}
\subsubsection{Sentence Splitter}
\subsubsection{Part of Speech}
\citet{toutanova2003tagger}
\subsubsection{Named Entity Recognition}
\citet{finkel2005incorporating}
\subsubsection{Dependency Parse}
\citet{chen2014nndep}
\subsubsection{Mention Resolver}

\subsubsection{Natural Logic Resolver}
\subsubsection{Coreference Resolution}
\citet{clark2015coref}

\subsection{Relation Extractor}
\citet{angeli2015openie}
